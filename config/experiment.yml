dataset: experiment
model_name: XGBoost # LinearModel, KNN, SVM, DecisionTree, RandomForest, XGBoost, CatBoost, LightGBM, ModelTree
                # MLP, TabNet, VIME, TabTransformer, RLN, DNFNet, STG, NAM, DeepFM, SAINT
objective: regression # Don't change

# GPU parameters
# use_gpu: False
# gpu_ids: [0, 1]
# data_parallel: True

# Optuna parameters - https://optuna.org/
# n_trials: 2
direction: minimize

# Cross validation parameters
# num_splits: 1
# shuffle: True
# seed: None

# Preprocessing parameters
scale: False
target_encode: False

# Training parameters
batch_size: 128
val_batch_size: 256
early_stopping_rounds: 20
epochs: 1000
logging_period: 100

# About the data
num_features: 13
num_classes: 1 # always one for regression!